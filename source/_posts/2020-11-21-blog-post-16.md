---
useMath: true
title: 'Bandit Algorithms'
mathjax: true
date: 2020-11-21
permalink: /posts/2020/11/blog-post-16/
tags:
  - Bandit
  - MDPs
  - Exploration
  - Explotation
  - Bound
---
# Bandit Algorithms

<!-- more -->

Decison-making with uncertainty is a challenge we all face, and bandits provide a simple model of this dilemma. Finding the right balance between exploration and exploitation is at the heart of all bandit problems.

## The Language of Bandits
A bandit problem is a sequential game between a learner and an environment. The game is played over $n$ rounds, where $n$ is a positive natural number called the ***horizon***. In each round $t \in [n]$, the learner first chooses an action $A_t$ from a given set $\mathcal{A}$, and the environment then reveals a reward $X_t \in \mathbb{R}$. 






### References
<a id="1">[1]</a> 
@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}


