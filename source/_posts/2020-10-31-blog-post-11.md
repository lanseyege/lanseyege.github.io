---
useMath: true
title: 'Probably Approximately Correct Learning'
mathjax: true
date: 2020-10-31
permalink: /posts/2020/10/blog-post-11/
tags:
  - PAC
  - Computational Learning Theory
  - VC-dimension
---

# Probably Approximately Correct Learning

<!-- more -->

## PAC learning model

PAC is used to formalize and address following questions:
  - What can be learned efficiently?
  - What is inherently hard to learn? 
  - How many examples are needed to learn successfully? 
  - Is there a general model of learning? 

We denote $\mathcal{X}$ be the set of all possible examples, input space. The set of all posible labels or targets is $\mathcal{Y}$. A *concept* $c : \mathcal{X} \rightarrow \mathcal{Y}$ is a mapping from $\mathcal{X}$ to $\mathcal{Y}$. A *concept class* is a set of concepts is denoted by $\mathcal{C}$. The learner considers a fixed set of possible concepts $\mathcal{H}$, called a *hypothesis set*, which might not necessarily coincide with $\mathcal{C}$. It 

**Generalization error** Given a hypothesis $h \in \mathcal{H}$, a target concept $c \in \mathcal{C}$, and an underlying distribution $\mathcal{D}$, the generalization error or risk of $h$ is defined by

$$
R(h) = \mathbb{P}_{x \sim \mathcal{D}} [h(x) \neq c(x)] = \mathbb{E}_{x \sim \mathcal{D}}[1_{h(x)\neq c(x)}]
$$

where $1_\omega$ is the indicator function of the event $\omega$. The generalization error of a hypothesis is not directly accessible to the learner, but learner can measure the *empirical error* of a hypothesis on the labeled sample $S$. 

***Empirical error*** Given a hypothesis $h \in \mathcal{H}$, a target concept $c \in \mathcal{C}$, and a sample $S = (x_1, \cdots, x_m)$, the empirical error or empirical risk of $h$ is defined by:

$$
\hat{R}_S(h) = \frac{1}{m}\sum_{i=1}^m 1_{h(x_i)\neq c(x_i)}
$$

Thus, the empirical error of $h \in \mathcal{H}$ is its average error over the sample $S$, while the generalization error is its expected error based on the distribution $\mathcal{D}$. For a fixed $h \in \mathcal{H}$, the expectation of the empirical error on $S$ is equal to the generalization error:

$$
\mathbb{E}_{S\sim \mathcal{D}^m}[\hat{R}_S(h)] = R(h)
$$

Indeed, by the linearity of the expectation and the fact that the sample is drawn i.i.d., we can write

$$
\mathbb{E}_{S\sim \mathcal{D}^m} [\hat{R}_S(h)] = \frac{1}{m}\sum_{i=1}^m \mathbb{E}_{S\sim \mathcal{D}^m}[1_{h(x_i) \neq c(x_i)}] = \frac{1}{m}\sum_{i=1}^m \mathbb{E}_{S\sim \mathcal{D}^m}[1_{h(x) \neq c(x)}]
$$

for any $x$ in sample $S$. Thus

$$
\mathbb{E}_{S\sim \mathcal{D}^m} [\hat{R}_S(h)] = \mathbb{E}_{S\sim \mathcal{D}^m} [1_{h(x) \neq c(x)}] = \mathbb{E}_{x\sim \mathcal{D}}[1_{h(x) \neq c(x)}] = R(h)
$$

***PAC-learning*** A concept class $\mathcal{C}$ is said to be PAC-learnable if there exists an algorithm $\mathcal{A}$ and a polynomial funcion $\text{poly}(\cdot, \cdot, \cdot)$ such that for any $\epsilon > 0$ and $\delta > 0$, for all distributions $\mathcal{D}$ on $\mathcal{X}$ and for any target concept $c\in \mathcal{C}$, the following holds for any sample size $m \geq \text{poly}(1/\epsilon, 1/\delta, \text{size}(c))$:

$$
\mathbb{P}_{S\sim \mathcal{D}^m} [R(h_S)\leq \epsilon] \geq 1-\delta
$$

If $\mathcal{A}$ futher runs in $\text{poly}(1/\epsilon, 1/\delta, \text{size}(c))$, then $\mathcal{C}$ is said to be efficiently PAC-learnable. When such an algorithm $\mathcal{A}$ exists, it is called a PAC-learning algorithm for $\mathcal{C}$. 


### Another explanation: [[2]](#2)
$\mathcal{C}$: Concept class; $L$: Learner; $H$: Hypothesis space; $n = \lvert H \rvert$, size of hypothesis space; $D$: distribution over inputs; $0 \leq \epsilon \leq \frac{1}{2}$: error goal; $0 \leq \delta \leq \frac{1}{2}$: certainty goal. 

***Probably $(1-\delta)$ Approximately $(\epsilon)$ Correct $(\text{error}_{D}(h))$*** 

$\mathcal{C}$ is PAC-learnable by $L$ using $H$ iff learner $L$ will with probability $1-\delta$, output a hypothesis $h\in H$ such that $\text{error}_D(h) \leq \epsilon$ in time and samples polynomial 

### Third explaination: [[3]](#3)
Probably approximately correct (PAC) learning theory helps analyze whether and under what conditions a learner $L$ will probably output an approximately correct classifier.

First, let's define "approximate." A hypothesis $h \in H$ is *approximately correct* if its error over the distribution of inputs is bounded by some $\epsilon$, $0\leq \epsilon \leq \frac{1}{2}$. I.e., $\text{error}_D(h) \leq \epsilon$, where $D$ is the distribution over inputs. 

Next, "probably." If $L$ will output such a classifier with probability $1-\delta$, with $0\leq \delta \leq \frac{1}{2}$, we call that classifier *probably* approximately correct.

Knowing that a target concept is PAC-learnable allows you to bound the sample size necessary to probably learn an approximately correct classifier, which is what's shown in the formula you've reproduced:

$$
m \geq \frac{1}{\epsilon}(\ln \lvert H \rvert + \ln \frac{1}{\delta})
$$


### Shattering, VC-dimension
When the hypothesis spaces are infinite, the VC-dimension provides such a measure. 

***Definition: Shattering (1)*** $H[S]$ - the set of splittings of dataset $S$ using concepts from $H$. $H$ shatters $S$ if $\lvert H[S] \rvert = 2^{\lvert S\rvert}$. 

A set of points $S$ is shattered by $H$ is there are hypotheses in $H$ that split $S$ in all of the $2^{\lvert S\rvert}$ possible ways; i.e., all possible ways of classifying points in $S$ are achievable using concepts in $H$. 

***Definition: Shattering (2)*** A set $S$ of size of $m$ is shattered by $\mathcal{H}$ if $\lvert \Pi_{\mathcal{H}}(S)\rvert = 2^m$, i.e. all possible labelings of the set $S$ are realized by function in $\mathcal{H}$.

***Definition: VC-dimension (1)*** The VC-dimension of a hypothesis space $H$ is the cardinality of the largest set $S$ that can be shattered by $H$. If arbitraily large finite sets can be shattered by $H$, then $\text{VCdim}(H)=\infty$. 

***Definition: VC-Dimension (2)*** VC-dim($\mathcal{H}$) = cardinality of the largest set shattered by $\mathcal{H}$. 

### References

<a id="1">[1]</a> 
@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018}
}

<a id="2">[2]</a> 
https://www.youtube.com/watch?v=e37nlms7Zi0

<a id="3">[3]</a> 
https://stats.stackexchange.com/questions/142906/what-does-pac-learning-theory-mean