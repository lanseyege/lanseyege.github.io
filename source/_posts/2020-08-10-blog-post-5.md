---
useMath: true
title: 'Stein Variational Gradient Decsent: RHKS'
mathjax: true
date: 2020-08-10
permalink: /posts/2020/08/blog-post-5/
tags:
  - Stein
  - SVGD 
  - RHKS
---
# Stein Variational Gradient Descent: RHKS

<!-- more -->

## Reproducing Hilbert Kernel Space (RHKS)

Before we start SVGD, we should overview some basic concepts in mathamatics. The RHKS will be the first to be introduced here. 

### Hilbert Space

***Definition (Inner Product)*** Let $\mathcal{H}$ be a vector space over $\mathcal{R}$. A function $\langle\cdot, \cdot\rangle_{\mathcal{H}}: \mathcal{H} \times \mathcal{H} \rightarrow \mathbb{R}$ is said to be an inner product on $\mathcal{H}$ if 

  - $\langle \alpha_1 f_1 + \alpha_2 f_2, g \rangle_\mathcal{H} = \alpha_1 \langle f_1, g \rangle_\mathcal{H} + \alpha_2 \langle f_2, g \rangle_\mathcal{H}$
  - $\langle f, g \rangle_\mathcal{H} = \langle g, f \rangle_\mathcal{H}$
  - $\langle f, f \rangle_\mathcal{H} \geq 0$ and $\langle f, f \rangle_\mathcal{H} = 0$ if and only if $f = 0$

***Definition (Hilbert Space)*** A Hilbert Space is an inner product space that is complete and separable with respect to the norm defined by the inner product. 

***Definition (Reproducing Kernel)*** Let $\mathcal{F}$ be a Hilbert function space over $\mathcal{X}$. A reproducing kernel of $\mathcal{F}$ is a function $k : \mathcal{X} \times \mathcal{X} \rightarrow \mathcal{R}$ which satisfies the following two properties:

  - $k(\cdot, x) \in \mathcal{F}$ for any $x \in \mathcal{X}$.
  - (Reproducing property) For any $f \in \mathcal{F}$ and any $x \in \mathcal{X}, f(x) = \langle f, k(\cdot, x)\rangle_\mathcal{F}$.

***Theorem*** Let $\mathcal{F}$ be a Hilbert function space over $\mathcal{X}$. The following are equivalent:

  - $\mathcal{F}$ has a reproducing kernel. 
  - For any $x \in \mathcal{X}$, the function $\delta_x : \mathcal{F} \rightarrow \mathcal{R}$ defined by $\delta_x(f) = f(x)$ is continuous.

***Remark*** The space of function $\delta_x$ forms the dual space $\mathcal{F}^\star$ of $\mathcal{F}$. 


***Definition*** Let $\mathcal{F}$ be a Hilbert function space over $\mathcal{X}$, we say $\mathcal{F}$ is a reproducing kernel Hilbert space over $\mathcal{X}$ if it satisfies the conditions of the previous theorem. 

***Theorem (Riesz Representation Theorem)*** Let $\mathcal{F}$ be a Hilbert space and $L : \mathcal{F} \rightarrow \mathcal{R}$ be a linear functional on $\mathcal{F}$ (The space of $L$ is dual space $\mathcal{F}^\star$ of $\mathcal{F}$). Then $L$ is continuous if and only if there exists $\Phi \in \mathcal{F}$ such that $L(f) = \langle f, \Phi \rangle_\mathcal{F}$ for any $f \in \mathcal{F}$. 

 
 ***Theorem*** Let $k : \mathcal{X} \times \mathcal{X} \rightarrow \mathcal{R}$. Then $k$ is a kernel if and only if $k$ is a reproducing kernel of some RKHS $\mathcal{F}$ over $\mathcal{X}$. 
 
 ***Lemma*** If $k$ is a kernel, then it has a feature space $\tilde{\mathcal{F}}$ and a feature map $\tilde{\Phi}: \mathcal{X} \rightarrow \tilde{\mathcal{F}}$ such that the map $\mathcal{V}: \tilde{\mathcal{F}} \mapsto(\mathcal{X} \mapsto \mathbb{R})$ (the range of $\mathcal{V}$ is the set of functions from $\mathcal{X}$ to $\mathcal{R}$) given by
 
 \begin{equation}
 \mathcal{V}(\omega) = \langle \omega, \tilde{\Phi}(\cdot) \rangle_\tilde{\mathcal{F}}
 \end{equation}
 
 is injective. 
 
***Theorem*** If $\mathcal{F}$ is a RKHS, then it has a unique reproducing kernel. 

***Theorem*** Let $k$ be a kernel on $\mathcal{X}$, and let $\mathcal{F}_0$ and $\Phi_0: \mathcal{X} \rightarrow \mathcal{F}_0$ be an associated feature space and feature map, respectively, such that the mapping $$\mathcal{V}: \mathcal{F}_0 \rightarrow \mathcal{F} = \left\{f = \langle \omega, \Phi_0(\cdot) \rangle_{\mathcal{F}_0} \vert \omega \in \mathcal{F}_0\right\}$$ is injective, whose existence is guarenteed by Lemma. Then,

  - $\mathcal{F}$ is the unique RKHS with $k$ as its reproducing kernel. 
  - The set $\mathcal{F}_\text{pre} = \left\{\sum_{i=1}^n \alpha_i k(\cdot, x_i)\vert n \in \mathcal{N}, \alpha_i \in \mathcal{R}, x_i \in \mathcal{X}\right\}$ is dense in $\mathcal{F}$. 
  - For $f, f^\prime \in \mathcal{F}_\text{pre}$ with $f = \sum_{i=1}^n \alpha_i k(\cdot, x_i)$ and $f^\prime = \sum_{i=1}^{n^\prime}\alpha_{i}^{\prime}k(\cdot, x_{i}^{\prime})$, $\langle f, f^\prime \rangle_\mathcal{F} = \sum_{i=1}^{n} \sum_{j=1}^{n^\prime} k(x_i, x_{j}^{\prime})$
  
 ***Definition*** A kernel $k(x, x^\prime)$ is said to be integrally strictly positive definition, if for any function $g$ that satisfies $$0 < \left\|g \right\|_2^2 < \infty$$,
 
 $$
 \begin{equation}
 \int_{\mathcal{X}} g(x)k(x, x^\prime)g(x^\prime)dxdx^\prime > 0
 \end{equation}
 $$
 
 
# References

<a id="1">[1]</a>
Fox, R., Pakman, A., and Tishby, N. Taming the noise in reinforcement learning via soft updates. In Conf. on Uncertainty in Artificial Intelligence, 2016.

<a id="2">[2]</a>
Schulman, J., Abbeel, P., and Chen, X.  Equivalence be-tween policy gradients and soft Q-learning.arXiv preprintarXiv:1704.06440, 2017a.

<a id="3">[3]</a>
Liu, Q. and Wang, D. Stein variational gradient descent: A general purpose bayesian inference algorithm. In Advances In Neural Information Processing Systems, pp. 2370â€“2378, 2016
