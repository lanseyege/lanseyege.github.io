---
useMath: true
title: ' Notes on book "Simulation (Fifth Edition)" '
mathjax: true
date: 2021-02-13
permalink: /posts/2021/02/blog-post-38/
tags:
  - Simulation
  - Statistic
---

# Simulation - Chp 12 : Markov Chain Monte Carlo Methods

<!-- more -->

## 12.1 Markov Chains

Consider a collection of random variables $X_0, X_1, \ldots$. If there exists a set of numbers $P_{ij}, i,j = 1, \ldots, N$, such that whenever the process is in state $i$ then, independent of the past states, the probability that the next state is $j$ is $P_{ij}$, then we say that the collection $\{X_n, n \geq 0\}$ constitutes a **Markov chain** having transition probabilities $P_{ij}, i,j = 1, \ldots, N$. 

A Markov chain is said to be irreducible if for each pair of states $i$ and $j$ there is a positive probability, starting in state $i$, that the process will ever enter state $j$. For an irreducible Markov chain, let $\pi_{j}$ denote the long-run proportion of time that the process is in state $j$. 

$$
\begin{array}{ll}
\pi_j &= \sum_{i=1}^N \pi_i P_{ij}, \quad j = 1, \ldots, N \\
\sum_{j=1}^N \pi_j &= 1 \\
\end{array}
$$

The $\{\pi_j\}$ are often called the **stationary probabilities** of the Markov chain. 

An irreducible Markov chain is said to be aperiodic if for some $n \geq 0$ and some state $j$,

$$
P\{X_n = j | X_0 = j\} > 0 \text{ and } P\{X_{n+1} = j | X_0 = j \} > 0 
$$

When $\pi_i P_{ij} = \pi_j P_{ji}, \forall i \neq j$, the Markov chain is said to be **time reversible**.


## 12.2 The Hastings-Metropolis Algorithm 

Let $b(j), j = 1, \ldots, m$ be positive numbers, and $B = \sum_{j=1}^m b(j)$. Suppose that $m$ is large and $B$ is difficult to calculate, and that we want to simulate a random variable (or a sequence of random variables) with probability mass function

$$
\pi(j) = b(j) / B, j = 1, \ldots, m
$$

One way of simulating a sequence of random variables whose distributions converge $\pi(j), j =1, \ldots, m$, is to find a Markov chain that is easy to simulate and whose limiting probabilities are the $\pi(j)$. The **Hastings-Metropolis algorithm** provides an approach for accomplishing this task. 

Let $Q$ be an irreducible Markov transition probability matrix on the integers $1, \ldots, m$, with $q(i,j)$, representing the row $i$, column $j$ element of $Q$. Now define a Markov chain $\{X_n , n \geq 0\}$ as follows. When $X_n = i$, a random variable $X$ such that $P\{X=j\} = q(i, j), j = 1, \ldots, m$, is generated. If $X = j$, then $X_{n+1}$ is set equal to $j$ with probability $\alpha (i, j)$ and is set equal to $i$ with probability $1 - \alpha (i, j)$. Under these conditions, it is easy to see that the sequence of states will constitute a Markov chain with transition probabilities $P_{ij}$ given by 

$$
\begin{array}{ll}
P_{i,j} = q(i,j) \alpha (i, j), \quad \text{if } j \neq i \\ 
P_{i,i} = q(i, i) + \sum_{k \neq i} q(i, k) (1 - \alpha (i, k)) \\
\end{array}
$$

Now this Markov chain will be time reversible and have stationary probabilities $\pi(j)$ if 

$$
\pi(i) P_{i,j} = \pi(j) P_{j,i} \quad \forall j \neq i
$$

which is equivalent to 

$$
\pi(i) q(i,j) \alpha(i,j) = \pi(j) q(j, i) \alpha (j, i)
$$

It is now easy to check that this will be satisfied if we take 

$$
\alpha(i,j) = \min \left(\frac{\pi(j)q(j,i)}{\pi(i)q(i,j)} , 1\right) = \min \left(\frac{b(j)q(j,i)}{b(i)q(i,j)} , 1\right)
$$

Note that if $\alpha (i,j) = \pi(j) q(j,i) / \pi(i)q(i,j)$ then $\alpha(j,i) = 1$, and vice versa. We should note that the value of $B$ is not needed to define the Markov chain, as the values $b(j)$ suffice. 

The following sums up the Hastings-Metropolis algorithm for generating a time-reversible Markov chain whose limiting probabilities are $\pi(j) = b(j) / B, j = 1, \ldots, m$. 

  1. Choose an irreducible Markov transition probability matrix $Q$ with transition probabilities $q(i, j), i,j = 1, \ldots,  m$. Also, choose some integer value $k$ between $1$ and $m$. 
  2. Let $n = 0$ and $X_0 = k$.
  3. Generate a random variable $X$ such that $P\{X = j\} = q(X_n, j)$ and generate a random number $U$. 
  4. If $U < [b(X)q(X, X_n)] / [b(X_n)q(X_n, X)],$ then $NS = X$; else $NS = X_n$.
  5. $n = n + 1, X_n = NS$.
  6. Go to $3$. 


## 12.3 The Gibbs Sampler 

The most widely used version of the Hastings-Metropolis algorithm is the **Gibbs sampler**. 

## 12.4 Continuous time Markov Chains and a Queueing Loss Model

## 12.5 Simulated Annealing 

## 12.6 The Sampling Importance Resampling Algorithm

## 12.7 Coupling from the Past 


# References

<a id="1">[1]</a> 
SIMULATION 5TH EDITION SHELDON ROSS 

